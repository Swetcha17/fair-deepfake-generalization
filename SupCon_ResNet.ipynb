{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c4fccd7-c623-4481-b586-3bfd8addb241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61b0c10f-6020-47d0-bc60-0d40ecbea29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SupCon ResNet with projection head\n",
    "class SupConResNet(nn.Module):\n",
    "    def __init__(self, base_model='resnet18', projection_dim=128):\n",
    "        super().__init__()\n",
    "        self.encoder = getattr(models, base_model)(weights=None)\n",
    "        self.encoder.fc = nn.Identity()\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, projection_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.encoder(x)\n",
    "        feat = F.normalize(self.projection_head(feat), dim=1)\n",
    "        return feat\n",
    "\n",
    "# Linear Classifier \n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, feat_dim, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(feat_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d2ef00c-5799-48ec-9c4f-d38c2e60c825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SupCon ResNet \n",
    "def train_supcon(data_dirs, model_path, epochs=20):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "    ])\n",
    "    datasets_list = [datasets.ImageFolder(path, transform=transform) for path in data_dirs]\n",
    "    train_dataset = ConcatDataset(datasets_list)\n",
    "    loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "    model = SupConResNet().to(device)\n",
    "    criterion = SupConLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            features = model(x)\n",
    "            loss = criterion(features, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"[SupCon] Epoch {epoch+1}: Loss = {total_loss / len(loader):.4f}\")\n",
    "\n",
    "    os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    return model\n",
    "\n",
    "# Extract features for classifier or t-SNE \n",
    "def extract_embeddings(model, dataloader):\n",
    "    model.eval()\n",
    "    feats, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            feat = model(x)\n",
    "            feats.append(feat.cpu())\n",
    "            labels.extend(y)\n",
    "    return torch.cat(feats), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "302fa17c-5b8b-4bb0-b25c-2c9d216a48e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train linear classifier \n",
    "def train_linear_classifier(encoder, data_dirs, save_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "    ])\n",
    "    datasets_list = [datasets.ImageFolder(path, transform=transform) for path in data_dirs]\n",
    "    dataset = ConcatDataset(datasets_list)\n",
    "    loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    features, labels = extract_embeddings(encoder, loader)\n",
    "    classifier = LinearClassifier(feat_dim=features.shape[1]).to(device)\n",
    "    optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(10):\n",
    "        classifier.train()\n",
    "        out = classifier(features.to(device))\n",
    "        loss = criterion(out, labels.to(device))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"[Linear] Epoch {epoch+1}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "    torch.save(classifier.state_dict(), save_path)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d3fe497-e9c8-4059-a0b9-be79277e28cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE Plot \n",
    "def plot_tsne(model, data_dir, save_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "    ])\n",
    "    dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "    loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    feats, labels = extract_embeddings(model, loader)\n",
    "    tsne = TSNE(n_components=2).fit_transform(feats.numpy())\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    scatter = plt.scatter(tsne[:, 0], tsne[:, 1], c=labels.numpy(), cmap='coolwarm', alpha=0.7)\n",
    "    plt.legend(*scatter.legend_elements(), title=\"Classes\")\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    plt.title(\"t-SNE on SupCon Features\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23270893-969d-4093-800f-7038aee8e456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def evaluate_open_set(model, classifier, data_dir, thresholds=np.arange(0.5, 0.96, 0.05)):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "    ])\n",
    "    dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "    loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    feats, labels = extract_embeddings(model, loader)\n",
    "    logits = classifier(feats.to(device)).softmax(dim=1).cpu().numpy()\n",
    "    y_true = labels.numpy()\n",
    "    y_scores = logits[:, 1]\n",
    "\n",
    "    best_f1, best_threshold, results = -1, None, {}\n",
    "    for thresh in thresholds:\n",
    "        conf = np.max(logits, axis=1)\n",
    "        pred = np.argmax(logits, axis=1)\n",
    "        pred = np.where(conf >= thresh, pred, -1)\n",
    "        mask = pred != -1\n",
    "        y_eval = y_true[mask]\n",
    "        p_eval = pred[mask]\n",
    "\n",
    "        if len(y_eval) == 0:\n",
    "            acc = f1 = float('nan')\n",
    "        else:\n",
    "            acc = accuracy_score(y_eval, p_eval)\n",
    "            f1 = f1_score(y_eval, p_eval)\n",
    "\n",
    "        results[round(thresh, 2)] = {\n",
    "            'Accuracy': acc, 'F1': f1, 'Rejected': len(y_true) - len(y_eval)\n",
    "        }\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = thresh\n",
    "\n",
    "    try:\n",
    "        auroc = roc_auc_score(y_true, y_scores)\n",
    "    except:\n",
    "        auroc = float('nan')\n",
    "\n",
    "    return {\n",
    "        'Best Threshold': best_threshold,\n",
    "        f'F1@{round(best_threshold, 2)}': best_f1,\n",
    "        'AUROC': auroc,\n",
    "        'Threshold Scores': results\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "914c4591-8320-40e2-ad16-4648f127fdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training without White...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'SupConLoss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m encoder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrained_Models/supcon_encoder_excl_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mleft_out_race\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m classifier_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrained_Models/supcon_classifier_excl_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mleft_out_race\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 12\u001b[0m encoder \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_supcon\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dirs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m classifier \u001b[38;5;241m=\u001b[39m train_linear_classifier(encoder, train_dirs, classifier_path)\n\u001b[1;32m     15\u001b[0m plot_tsne(encoder, test_dir, save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlots/supcon_tsne_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mleft_out_race\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 15\u001b[0m, in \u001b[0;36mtrain_supcon\u001b[0;34m(data_dirs, model_path, epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m SupConResNet()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 15\u001b[0m criterion \u001b[38;5;241m=\u001b[39m \u001b[43mSupConLoss\u001b[49m()\n\u001b[1;32m     16\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SupConLoss' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    all_races = [\"White\", \"Black\", \"Indian\", \"East_Asian\", \"Southeast_Asian\", \"Latino_Hispanic\"]\n",
    "\n",
    "    for left_out_race in all_races:\n",
    "        print(f\"\\nTraining without {left_out_race}...\")\n",
    "        train_dirs = [f\"{r}_augmented\" for r in all_races if r != left_out_race]\n",
    "        test_dir = f\"{left_out_race}\"\n",
    "\n",
    "        encoder_path = f\"Trained_Models/supcon_encoder_excl_{left_out_race}.pth\"\n",
    "        classifier_path = f\"Trained_Models/supcon_classifier_excl_{left_out_race}.pth\"\n",
    "\n",
    "        encoder = train_supcon(train_dirs, encoder_path)\n",
    "        classifier = train_linear_classifier(encoder, train_dirs, classifier_path)\n",
    "\n",
    "        plot_tsne(encoder, test_dir, save_path=f\"Plots/supcon_tsne_{left_out_race}.png\")\n",
    "\n",
    "        metrics = evaluate_open_set(encoder, classifier, test_dir)\n",
    "        flat_metrics = {\n",
    "            'Race': left_out_race,\n",
    "            'Best Threshold': metrics['Best Threshold'],\n",
    "            f\"F1@{metrics['Best Threshold']}\": metrics[f\"F1@{metrics['Best Threshold']}\"],\n",
    "            'AUROC': metrics['AUROC']\n",
    "        }\n",
    "\n",
    "        csv_path = \"Plots/supcon_open_set_results.csv\"\n",
    "        if os.path.exists(csv_path):\n",
    "            df_existing = pd.read_csv(csv_path)\n",
    "            df = pd.concat([df_existing, pd.DataFrame([flat_metrics])], ignore_index=True)\n",
    "        else:\n",
    "            df = pd.DataFrame([flat_metrics])\n",
    "        df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417e76ec-6095-4b09-8d9c-c318f37edb15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
